# Intelig√™ncia Artificial e Deep Learning

## üìñ Vis√£o Geral

Deep Learning revolucionou a IA moderna, permitindo que modelos aprendam representa√ß√µes hier√°rquicas complexas de dados. Este documento compila aprendizados sobre arquiteturas, t√©cnicas e aplica√ß√µes de deep learning.

## üß† Arquiteturas Fundamentais

### Redes Neurais Convolucionais (CNNs)

**Aplica√ß√µes**: Computer vision, image classification, object detection

**Conceitos-chave**:
- **Camadas convolucionais**: Extraem features locais
- **Pooling**: Reduz dimensionalidade preservando informa√ß√£o
- **Feature maps**: Representa√ß√µes hier√°rquicas da imagem

**Exemplo - Classifica√ß√£o Aut√¥noma de Imagens**:
```
Arquitetura:
Input (224x224x3) 
  ‚Üí Conv2D (64 filters) 
  ‚Üí MaxPool 
  ‚Üí Conv2D (128 filters)
  ‚Üí MaxPool
  ‚Üí Dense (1024)
  ‚Üí Dropout (0.5)
  ‚Üí Output (num_classes)
```

**Aplica√ß√µes pr√°ticas**:
- Classifica√ß√£o de imagens m√©dicas (raios-X, resson√¢ncia)
- Reconhecimento facial
- Inspe√ß√£o de qualidade em manufatura

### Transformers e Attention Mechanisms

**Revolu√ß√£o**: Substitu√≠ram RNNs/LSTMs em muitas tarefas

**Self-Attention**:
- Cada token "atende" a todos os outros
- Captura depend√™ncias de longo alcance
- Paraleliz√°vel (ao contr√°rio de RNNs)

**Multi-Head Attention**:
```python
# Conceptual
Q, K, V = query, key, value projections
Attention(Q,K,V) = softmax(QK^T / sqrt(d_k)) * V

# Multiple heads capture different patterns
MultiHead = Concat(head_1, ..., head_h) * W^O
```

**Aplica√ß√µes**:
- NLP (BERT, GPT, T5)
- Computer vision (Vision Transformers - ViT)
- Time series forecasting

### Hybrid Architectures

**Spiking Neural Networks (SNNs) + Quantum**:
- Inspiradas no c√©rebro humano
- Efici√™ncia energ√©tica superior
- Integra√ß√£o com computa√ß√£o qu√¢ntica

**Parameter Efficient Hybrid**:
- Combina SNN com quantum data re-upload
- Reduz par√¢metros tre using surrogate gradients
- √ötil para hardware limitado (edge devices)

## üöÄ T√©cnicas de Otimiza√ß√£o

### Continual Learning

**Desafio**: Aprender novas tarefas sem esquecer antigas (catastrophic forgetting)

**Shared LoRA Subspaces**:
- Low-Rank Adaptation (LoRA) para fine-tuning eficiente
- Subespa√ßos compartilhados entre tarefas
- Almost Strict Continual Learning sem replay

**Benef√≠cios**:
- Adapta√ß√£o r√°pida a novos dom√≠nios
- Menor overhead de mem√≥ria
- Preserva conhecimento anterior

### Combating Data and Target Shifts

**Problema**: Modelos degradam quando distribui√ß√£o muda (distribution shift)

**T√©cnicas**:
1. **Domain Adaptation**
   - Alinha distribui√ß√µes source e target
   - Adversarial training

2. **Test-Time Adaptation**
   - Ajusta modelo durante infer√™ncia
   - Sem acesso a labels

3. **Self-Training**
   - Pseudo-labels em dados target
   - Iterative refinement

### Enhancing Abstractiveness in Summarization

**Calibrated Distillation**:
- Treina modelo menor a partir de ensemble
- Calibra√ß√£o de confian√ßa (temperature scaling)
- Gera sum√°rios mais abstratos, menos extrativos

**Pipeline**:
```
1. Ensemble de modelos grandes gera distribui√ß√µes
2. Calibra√ß√£o via temperature tuning
3. Distila√ß√£o para modelo compacto
4. Fine-tuning com abstractiveness reward
```

## üî¨ Aplica√ß√µes Espec√≠ficas

### Computer Vision

#### Flow3r - Visual Geometry Learning

**Inova√ß√£o**: Factored flow prediction escal√°vel

**Arquitetura**:
- Prediz optical flow entre frames
- Decomposi√ß√£o fatorada para escala
- Aplica√ß√µes em 3D reconstruction

**Casos de uso**:
- Rob√≥tica (navega√ß√£o visual)
- Carros aut√¥nomos
- AR/VR tracking

#### VideoWorld 2 - Transferable Knowledge

**Objetivo**: Aprender representa√ß√µes de v√≠deos real-world transfer√≠veis

**Abordagem**:
- Self-supervised learning em large-scale video
- Temporal consistency constraints
- Transfer para downstream tasks (action recognition, etc.)

### Ci√™ncias Biol√≥gicas

#### Chlamy_ChloroPred

**Aplica√ß√£o**: Predi√ß√£o de prote√≠nas de cloroplasto

**M√©todo**:
- Deep learning binary classifier
- Alta acuracybelt para Chlamydomonas reinhardtii
- Potencial cross-proteome versatility

**Import√¢ncia**:
- Acelera pesquisa em bioenergia
- Identifica√ß√£o de alvos farmacol√≥gicos
- Engenharia de microalgas

### Imagens M√©dicas

#### Water-Unsuppressed MRSI

**Desafio**: MRI spectroscopic imaging com alta resolu√ß√£o

**Solu√ß√£o DL**:
- Deep learning para reconstru√ß√£o de imagens
- Ultra-high field (7T+)
- Quantifica√ß√£o simult√¢nea de:
  - Metab√≥litos
  - Susceptibilidade magn√©tica
  - Myelin water

**Benef√≠cios cl√≠nicos**:
- Diagn√≥stico precoce de doen√ßas neurol√≥gicas
- Monitoramento de tratamentos
- Pesquisa em neuroci√™ncia

## ‚ö° Reinforcement Learning

### AutoGrid AI

**Dom√≠nio**: Gerenciamento aut√¥nomo de microgrids

**Framework**:
- Deep Reinforcement Learning
- Multi-objective optimization:
  - Custo de energia
  - Emiss√µes de carbono
  - Confiabilidade

**Algoritmo**:
```
Estado: [energy_demand, prices, battery_soc, solar_gen, grid_status]
A√ß√µes: [charge_battery, discharge_battery, buy_grid, sell_grid]
Reward: -cost - carbon_penalty + reliability_bonus
```

**Resultados**:
- At√© 30% redu√ß√£o em custos vs baseline
- Menor pegada de carbono
- Maior resili√™ncia

### Multi-Agent Systems

**Potential Games Analysis**:
- Framework te√≥rico para coordena√ß√£o
- Price of Anarchy bounds
- Conex√£o com contrastive learning

**CommCP - Communication with Conformal Prediction**:
- Agentes coordenam via comunica√ß√£o baseada em LLM
- Conformal prediction para uncertainty quantification
- Eficiente mesmo com comunica√ß√£o limitada

## üìä Physics-Informed Neural Networks (PINNs)

### Conceito

Integra leis f√≠sicas (EDPs) diretamente na loss function:

```python
# Loss total
L_total = L_data + Œª_physics * L_physics + Œª_boundary * L_boundary

# Exemplo: Equa√ß√£o de calor
# ‚àÇu/‚àÇt = Œ± * ‚àÇ¬≤u/‚àÇx¬≤
L_physics = MSE(du_dt - alpha * d2u_dx2, 0)
```

### Implementa√ß√£o com Deep Learning

**Vantagens**:
- Menos dados necess√°rios
- Solu√ß√µes fisicamente plaus√≠veis
- Generaliza melhor para novos regimes

**Aplica√ß√µes**:
- Mec√¢nica dos fluidos
- Simula√ß√µes de materiais
- Previs√£o clim√°tica

## üõ†Ô∏è Ferramentas e Frameworks

### Desenvolvimento e Debugging

**PATe 2.0** - Histopathological Education:
- Plataforma escal√°vel para treinamento
- Deep learning para assisted learning
- Smart annotation tools

### Dataset Development

**A Very Big Video Reasoning Suite**:
- Large-scale benchmark para video understanding
- M√∫ltiplas tarefas (reasoning, temporal, spatial)
- Desafia SOT models

## üìö Refer√™ncias

### Arquiteturas e T√©cnicas
- [AI-Driven Autonomous Image Classification](https://github.com/ElioNeto/agregador)
- [Flow3r: Factored Flow Prediction](https://github.com/ElioNeto/agregador)
- [Shared LoRA Subspaces for Continual Learning](https://github.com/ElioNeto/agregador)
- [Parameter efficient hybrid spiking-quantum CNN](https://github.com/ElioNeto/agregador)

### Aplica√ß√µes
- [AutoGrid AI: Deep RL for Microgrid Management](https://github.com/ElioNeto/agregador)
- [Chlamy_ChloroPred: Chloroplast Protein Prediction](https://github.com/ElioNeto/agregador)
- [Deep learning water-unsuppressed MRSI](https://github.com/ElioNeto/agregador)
- [VideoWorld 2: Learning from Real-world Videos](https://github.com/ElioNeto/agregador)

### Teoria
- [On the Analysis of Potential Games](https://github.com/ElioNeto/agregador)
- [Implementing physics-informed neural networks](https://github.com/ElioNeto/agregador)
- [Combating Data and Target Shifts in Visual Tasks](https://github.com/ElioNeto/agregador)

## üîó Relacionado

- [LLMs e Modelos de Linguagem](llms.md)
- [Computer Vision](computer-vision.md)
- [GPU e Acelera√ß√£o](../hardware/gpu-aceleracao.md)
