# Testes, Debugging e Desenvolvimento de Software

## üìñ Vis√£o Geral

Pr√°ticas modernas de desenvolvimento exigem ferramentas e t√©cnicas sofisticadas para garantir qualidade, debugar problemas e manter produtividade.

## üß™ Gera√ß√£o Autom√°tica de Testes

### Rapid End-to-End Test Generation

**Desafio**: Testes E2E s√£o demorados para criar manualmente

**Solu√ß√£o com LLMs**:
```
User Story
  ‚Üì
LLM (GPT-4, Claude)
  ‚îú‚îÄ Gera test scenarios
  ‚îú‚îÄ Cria test code (Playwright, Selenium)
  ‚îî‚îÄ Adiciona assertions
  ‚Üì
Executa testes
  ‚Üì
Feedback Loop
  ‚îú‚îÄ Falhas ‚Üí Refina prompts
  ‚îî‚îÄ Sucesso ‚Üí Adiciona a suite
```

**Exemplo Prompt**:
```
Crie um teste E2E para:
- Login com credenciais v√°lidas
- Navegar para dashboard
- Verificar presen√ßa de widget "Sales"
- Fazer logout

Framework: Playwright + TypeScript
```

**Output**:
```typescript
import { test, expect } from '@playwright/test';

test('user can login and view dashboard', async ({ page }) => {
  await page.goto('https://app.example.com/login');
  
  await page.fill('[name="email"]', 'user@example.com');
  await page.fill('[name="password"]', 'password123');
  await page.click('button[type="submit"]');
  
  await expect(page).toHaveURL(/.*dashboard/);
  await expect(page.locator('.widget-sales')).toBeVisible();
  
  await page.click('[data-testid="logout-button"]');
  await expect(page).toHaveURL(/.*login/);
});
```

### Hallucination Mitigation

**Problema**: LLMs podem gerar testes com seletores incorretos

**Solu√ß√µes**:

1. **DOM Snapshot Validation**:
   ```
   LLM gera teste ‚Üí Valida seletores contra DOM real
   ```

2. **Iterative Refinement**:
   ```python
   for attempt in range(max_retries):
       test_code = llm.generate(prompt)
       result = run_test(test_code)
       if result.passed:
           break
       prompt += f"\nErro: {result.error}. Corrija o teste."
   ```

3. **Self-Healing Tests**:
   - Testes detectam elementos por m√∫ltiplos seletores
   - Fallback autom√°tico se um falha

## üîç Debugging Avan√ßado

### Automated Multi-Source Debugging

**Fontes de Informa√ß√£o**:
```
Error Message
  +
Stack Trace
  +
Logs (aplicativos, sistema)
  +
M√©tricas (CPU, mem√≥ria, rede)
  +
Code Context
  ‚Üì
LLM Analysis
  ‚Üì
Root Cause + Fix Suggestion
```

**Natural Language Error Explanation**:

**Input**:
```
Error: NullPointerException
  at UserService.getProfile(UserService.java:42)
  at ProfileController.show(ProfileController.java:18)

Code (linha 42):
return user.getAddress().getCity();
```

**Output**:
```
Problema: Null pointer ao acessar cidade do endere√ßo

Causa Raiz:
- Campo 'address' de 'user' √© null
- Provavelmente usu√°rio sem endere√ßo cadastrado

Corre√ß√£o Sugerida:
if (user.getAddress() != null) {
    return user.getAddress().getCity();
}
return "Cidade n√£o cadastrada";

Preven√ß√£o:
- Usar Optional<Address> no modelo
- Validar na cria√ß√£o de usu√°rio
- Adicionar constraint de banco de dados
```

### Root Cause Analysis com LLMs

**M√©todo**:

1. **Correlation Analysis**:
   ```
   Timeline:
   12:00 - Deploy da vers√£o 2.1.0
   12:05 - Spike em erro 500
   12:10 - Aumento de 3x em latency de DB
   
   ‚Üí LLM identifica: Deploy introduziu N+1 query
   ```

2. **Code Diff Analysis**:
   ```diff
   - for (User user : users) {
   -     user.getOrders();  // 1 query por user
   - }
   + users = userRepo.findAllWithOrders();  // 1 query total
   ```

3. **Knowledge Base Search**:
   - Busca incidentes similares passados
   - Sugere solu√ß√µes que funcionaram

## üí° AnoMod - Anomaly Detection Dataset

### Objetivo

Dataset para treinar modelos de detec√ß√£o de anomalias em sistemas

### Conte√∫do

**Cenrios Incluidos**:
1. **Memory Leak**
   - M√©tricas: Mem√≥ria crescente linearmente
   - Sintomas: OOM errors eventual

2. **CPU Thrashing**
   - M√©tricas: Context switches elevados
   - Sintomas: Latency alta, throughput baixo

3. **Network Saturation**
   - M√©tricas: Packet loss, retransmissions
   - Sintomas: Timeouts, failures intermitentes

4. **Database Deadlocks**
   - M√©tricas: Lock wait time
   - Sintomas: Transa√ß√µes travadas

### Uso para Treinamento

```python
import pandas as pd
from sklearn.ensemble import IsolationForest

# Carrega dataset
df = pd.read_csv('anomod/memory_leak.csv')

# Features
X = df[['mem_used', 'mem_growth_rate', 'gc_frequency']]

# Treina detector
model = IsolationForest(contamination=0.1)
model.fit(X)

# Predi√ß√£o
y_pred = model.predict(X_test)
# -1 = anomalia, 1 = normal
```

## üõ†Ô∏è Ferramentas Modernas

### AgentCgroup - Controle de Recursos de AI

**Problema**: Agentes de IA consomem recursos descontroladamente

**Solu√ß√£o**: Cgroups para limitar recursos

```bash
# Cria cgroup para agente IA
sudo cgcreate -g cpu,memory:ai-agent

# Limita CPU a 50% e mem√≥ria a 2GB
sudo cgset -r cpu.cfs_quota_us=50000 ai-agent
sudo cgset -r memory.limit_in_bytes=2G ai-agent

# Executa agente no cgroup
sudo cgexec -g cpu,memory:ai-agent python ai_agent.py
```

**Benef√≠cios**:
- Previne que agente monopolize recursos
- Coexist√™ncia com outras aplica√ß√µes
- Melhor previsibilidade de performance

### Uncertainty Modeling (SysML v2)

**Aplica√ß√£o**: Modelagem de sistemas com incerteza

**Exemplo - Sistema de Navega√ß√£o**:
```sysml
part def NavigationSystem {
  // Par√¢metros com incerteza
  attribute gps_accuracy : Real 
    { distribution = Normal(mean=5.0, std=2.0); }
  
  attribute sensor_noise : Real
    { distribution = Exponential(lambda=0.1); }
  
  // Propaga incerteza
  calc position_uncertainty {
    return sqrt(gps_accuracy^2 + sensor_noise^2);
  }
}
```

**Benef√≠cios**:
- Especifica√ß√£o formal de incertezas
- Simula√ß√£o Monte Carlo autom√°tica
- Valida√ß√£o de requisitos probabilisticos

## üìä Impacto de IA Generativa

### Produtividade em Times √Ågeis

**Estudo Multi-Caso**:

**Ganhos Medidos**:
1. **Code Generation**: 35-45% mais r√°pido
   - Boilerplate (controllers, models)
   - Testes unit√°rios
   - Documenta√ß√£o

2. **Code Review**: 25% mais r√°pido
   - IA sugere melhorias
   - Identifica bugs potenciais
   - Verifica best practices

3. **Debugging**: 30% mais r√°pido
   - Explica√ß√µes de erros
   - Sugest√µes de fix
   - Contexto de stack trace

**Desafios**:
- **Over-reliance**: Desenvolvedores podem aceitar sugest√µes sem entender
- **Quality Variance**: Sugest√µes nem sempre corretas
- **Security**: Risco de gerar c√≥digo vulner√°vel

**Best Practices**:
```
1. Sempre revisar c√≥digo gerado
2. Usar IA como assistente, n√£o substituto
3. Validar sugest√µes com testes
4. Treinar time em limita√ß√µes de LLMs
```

## üîç Penetration Testing com LLMs

### What Makes a Good LLM Agent for Pentest?

**Capacidades Necess√°rias**:

1. **Reconnaissance**
   ```
   - Port scanning (nmap)
   - Service enumeration
   - Vulnerability scanning (Nessus, OpenVAS)
   ```

2. **Exploitation**
   ```
   - Metasploit integration
   - Custom exploit development
   - Payload generation
   ```

3. **Post-Exploitation**
   ```
   - Privilege escalation
   - Lateral movement
   - Data exfiltration
   ```

**Exemplo - Agente Aut√¥nomo**:
```python
class PentestAgent:
    def __init__(self, target):
        self.target = target
        self.llm = ChatGPT4()
        self.tools = ["nmap", "metasploit", "sqlmap"]
    
    def recon(self):
        prompt = f"""
        Target: {self.target}
        Objetivo: Enumera√ß√£o inicial
        Tools: {self.tools}
        
        Gere comandos de reconnaissance.
        """
        commands = self.llm.generate(prompt)
        results = [execute(cmd) for cmd in commands]
        return self.analyze_results(results)
    
    def exploit(self, vulnerabilities):
        for vuln in vulnerabilities:
            prompt = f"""
            Vulnerabilidade: {vuln}
            Gere exploit strategy.
            """
            strategy = self.llm.generate(prompt)
            if self.execute_exploit(strategy):
                return True
        return False
```

**Limita√ß√µes**:
- LLMs podem sugerir a√ß√µes il√©gicas
- Requer valida√ß√£o humana constante
- √âtica: Uso apenas em ambientes autorizados

## ‚ö° Observabilidade

### From Distributed Tracing to Proactive SLO

**Evolu√ß√£o**:
```
Traditional Monitoring (reativo)
  ‚Üì
Distributed Tracing (diagn√≥stico)
  ‚Üì
SLO Management (proativo)
```

**Proactive SLO**:

1. **Define SLOs**:
   ```yaml
   slo:
     - metric: request_latency_p99
       target: 200ms
       window: 30d
     - metric: error_rate
       target: 0.1%
       window: 30d
   ```

2. **Burn Rate Analysis**:
   ```
   Error Budget Remaining: 70%
   Current Burn Rate: 5%/day
   
   ‚Üí Alerta: At este ritmo, error budget esgota em 14 dias
   ```

3. **Predictive Alerts**:
   ```
   ML Model previu:
   - Latency aumentar√° 20% na pr√≥xima hora
   - SLO ser√° violado se nenhuma a√ß√£o for tomada
   
   A√ß√µes Sugeridas:
   - Escalar replicas do servi√ßo X
   - Aumentar cache TTL
   ```

## üìö Refer√™ncias

### Testes e Debugging
- [Rapid End-to-End Test Generation and Hallucination Mitigation](https://github.com/ElioNeto/agregador)
- [Automated Multi-Source Debugging](https://github.com/ElioNeto/agregador)
- [Root Cause Analysis Method Based on LLMs](https://github.com/ElioNeto/agregador)
- [AnoMod: Dataset for Anomaly Detection](https://github.com/ElioNeto/agregador)

### Ferramentas
- [AgentCgroup: Controlling OS Resources of AI Agents](https://github.com/ElioNeto/agregador)
- [Uncertainty Modeling for SysML v2](https://github.com/ElioNeto/agregador)

### Produtividade
- [Impacts of Generative AI on Agile Teams Productivity](https://github.com/ElioNeto/agregador)
- [What Makes a Good LLM Agent for Real-world Penetration Testing](https://github.com/ElioNeto/agregador)

### Observabilidade
- [From distributed tracing to proactive SLO management](https://github.com/ElioNeto/agregador)

## üîó Relacionado

- [Microservi√ßos - Observabilidade](../sistemas-distribuidos/microservicos.md#observabilidade)
- [IA Generativa](../ia-e-ml/ia-deep-learning.md)
- [Seguran√ßa - Penetration Testing](../seguranca/blockchain-cripto.md)
